{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1rEaOZWop50"
      },
      "outputs": [],
      "source": [
        "def preprocessing1(a):\n",
        "  a = a.lower()\n",
        "  a = a.replace(\" \",\"\")\n",
        "  punctuations = [\",\",\"!\",\"?\",\"'\",\"-\",\".\",\":\",\";\"]\n",
        "  a = \"\".join(x for x in a if not x in punctuations)\n",
        "  return a\n",
        "user_input = input(\"Enter any thing: \")\n",
        "user_input = preprocessing1(user_input)\n",
        "print(user_input)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏫ **ASSIGNMENT 4**"
      ],
      "metadata": {
        "id": "TKZsEHqaUDGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GlYsZyI-4i6",
        "outputId": "d5d76969-a7c3-46cb-ee23-39a7e138a9ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏬ **My Notes**\n",
        "Using nltk is better and easier as it has collection of stop words.\n",
        "Lemmatization was my first choice because stemming is quite rigid and often gives a word that does not exist however lemmatization saves that trouble!\n",
        "Also the autocorrector project in CPP could use NLTK too"
      ],
      "metadata": {
        "id": "t6jPpHaNUUpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textprocessing(b):\n",
        "  b = b.lower()\n",
        "  punctuations = [\",\",\"!\",\"?\",\"'\",\"-\",\".\",\":\",\";\"]\n",
        "  numbers = \"0123456789\"\n",
        "  b = \"\".join(x for x in b if not x in punctuations)\n",
        "  b = \"\".join(x for x in b if not x in numbers)\n",
        "  b = b.replace(\" \",\"\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yCTwxrptFpo",
        "outputId": "3003aa91-2078-444a-91fd-0bea16939620"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏬ **ASSIGNMENT 5**"
      ],
      "metadata": {
        "id": "de4tNEkfVdLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "def textprocessing(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = \"\".join(ch for ch in text if ch not in string.punctuation and not ch.isdigit())\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "\n",
        "    words = [w for w in words if len(w) >= 3]\n",
        "\n",
        "\n",
        "    tagged = nltk.pos_tag(words)\n",
        "    keep_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\",\n",
        "                 \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\",\n",
        "                 \"JJ\", \"JJR\", \"JJS\"}\n",
        "\n",
        "    filtered = [word for word, tag in tagged if tag in keep_tags]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "user_input = input(\"Enter text: \")\n",
        "\n",
        "print(textprocessing(user_input))"
      ],
      "metadata": {
        "id": "pfBfIoVzD-KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b181db-bf99-4844-a821-4815a5271c83"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: my program was not working\n",
            "['program', 'working']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⏬ **ASSIGNMENT 3**"
      ],
      "metadata": {
        "id": "rUo9pHofV7zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CHATBOT WITH MEMORY\n",
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLE_mKYFWGaO",
        "outputId": "a8022a0a-4f8b-41e1-e748-c42bad22ca68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get(\"TASK1\")\n",
        "\n",
        "client = Groq(api_key=api_key) # Pass api_key as a keyword argument\n",
        "def chatbot():\n",
        "    memory = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == \"quit\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "\n",
        "        messages = []\n",
        "        for exchange in memory:\n",
        "            messages.append({\"role\": \"user\", \"content\": exchange[\"user\"]})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": exchange[\"bot\"]})\n",
        "\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama3-8b-8192\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        bot_reply = response.choices[0].message.content\n",
        "        print(\"Chatbot:\", bot_reply)\n",
        "\n",
        "        memory.append({\"user\": user_input, \"bot\": bot_reply})\n",
        "\n",
        "\n",
        "        memory = memory[-5:]\n",
        "\n",
        "\n",
        "chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHhz1jhaXEym",
        "outputId": "5a31f07d-9e2d-43fc-bff1-d945865fa008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: i am stressed i sometimes forget how to call groq client api key\n",
            "Chatbot: I totally understand! It can be really frustrating when you're feeling stressed and struggling to remember important details like API keys. Here are a few strategies that might help:\n",
            "\n",
            "1. **Write it down**: Try writing your Groq client API key down in a safe place, like a notebook or a digital note-taking app. This way, you can refer back to it whenever you need it.\n",
            "2. **Create a secure note**: Consider creating a secure note on your password manager (like LastPass or 1Password) or a secure note-taking app (like Evernote or Simplenote). This way, you can store your API key securely and access it when needed.\n",
            "3. **Use a browser extension**: There are a few browser extensions available that can help you manage your API keys, such as LastPass Authenticator or 1Password Authenticator. These extensions can store your API keys securely and auto-fill them for you when you need them.\n",
            "4. **Break it down into smaller chunks**: If you're feeling overwhelmed by the sheer amount of information you need to remember, try breaking it down into smaller chunks. For example, you could write down just the API key itself, without the rest of the credentials. This can make it feel less daunting and more manageable.\n",
            "5. **Practice active recall**: Try actively recalling your API key by testing yourself to remember it. For example, you could ask yourself what your API key is, and then check your notes or password manager to see if you're correct.\n",
            "6. **Take a break**: Sometimes, taking a break and coming back to the task later can help you feel more focused and less stressed. Try taking a short walk, doing some deep breathing exercises, or engaging in another activity that helps you relax.\n",
            "7. **Use a mnemonic device**: If you're really struggling to remember your API key, try creating a mnemonic device to help you recall it. This could be a sentence or phrase that associates with the API key, for example.\n",
            "\n",
            "I hope these strategies help you feel less stressed and more able to recall your Groq client API key when you need it!\n",
            "You: in code it is supposed to be groq(api_key=api_key) why?\n",
            "Chatbot: The reason `groq(api_key=api_key)` is written in this way in code is primarily for two reasons:\n",
            "\n",
            "1. **Readability and maintainability**: By explicitly naming the parameter as `api_key`, it becomes clear what value is expected in that position. This makes the code more readable and easier to understand for others (including yourself when you need to revisit the code later).\n",
            "2. **Avoiding typos and errors**: When you use an unnamed parameter (e.g., `groq(api_key='my_api_key')`), it can be easy to accidentally misspell the parameter name or use the wrong value. By using a named parameter, you explicitly specify the name of the parameter, which helps catch typos and errors at runtime.\n",
            "\n",
            "For example, if you were to use the unnamed `groq` function, like this: `groq('my_api_key')`, it could be confusing to see that `my_api_key` is not a variable, but rather a direct value being passed to the `groq` function.\n",
            "\n",
            "By naming the parameter as `api_key`, you can avoid this confusion and make it clear what value is being passed to the function.\n",
            "\n",
            "Additionally, using named parameters can also make your code more conducive to refactoring or reorganizing, as you have more control over the mapping between function parameters and their values.\n",
            "\n",
            "So, to summarize, writing `groq(api_key=api_key)` in code makes it clearer, more readable, and more maintainable, which can ultimately save you time and reduce the risk of errors!\n",
            "You: ok thank you teach me how to make a chatbot using groq api\n",
            "Chatbot: What a great idea! I'd be happy to help you create a chatbot using the Groq API.\n",
            "\n",
            "Here's a step-by-step guide to get you started:\n",
            "\n",
            "**Prerequisites:**\n",
            "\n",
            "1. You need to have a Groq account and an API key. If you don't have one, create an account and get your API key.\n",
            "2. You'll need a programming language of your choice (e.g., Python, JavaScript, or Rust).\n",
            "3. Familiarity with the Groq API documentation and your chosen programming language is helpful but not necessary.\n",
            "\n",
            "**Step 1: Create a new project and install the necessary dependencies**\n",
            "\n",
            "For this example, we'll use Python. Create a new Python project (e.g., `groq_chatbot`) and install the required dependencies:\n",
            "\n",
            "* `groq` library: `pip install groq`\n",
            "* `flask` library (for a simple web server): `pip install flask`\n",
            "* `nltk` library (for natural language processing): `pip install nltk`\n",
            "\n",
            "**Step 2: Set up your Groq API key and credentials**\n",
            "\n",
            "Create a new file named `config.py` and add the following code:\n",
            "```python\n",
            "import os\n",
            "\n",
            "API_KEY = 'YOUR_GROQ_API_KEY'  # Replace with your actual API key\n",
            "API_SECRET = 'YOUR_GROQ_API_SECRET'  # Replace with your actual API secret\n",
            "Groq = groq.Groq(api_key=API_KEY, api_secret=API_SECRET)\n",
            "```\n",
            "Make sure to replace `YOUR_GROQ_API_KEY` and `YOUR_GROQ_API_SECRET` with your actual Groq API key and secret.\n",
            "\n",
            "**Step 3: Define your chatbot's conversation flow**\n",
            "\n",
            "Create a new file named `conversation.py` and define your chatbot's conversation flow using the Groq API. For this example, we'll create a simple chatbot that responds to basic user input.\n",
            "\n",
            "```python\n",
            "import groq\n",
            "from nltk.tokenize import word_tokenize\n",
            "from nltk.stem import WordNetLemmatizer\n",
            "\n",
            "lemmatizer = WordNetLemmatizer()\n",
            "\n",
            "class Chatbot:\n",
            "    def __init__(self, Groq):\n",
            "        self.Groq = Groq\n",
            "\n",
            "    def process_input(self, input_text):\n",
            "        # Tokenize the input text\n",
            "        tokens = word_tokenize(input_text)\n",
            "\n",
            "        # Lemmatize the tokens\n",
            "        lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
            "\n",
            "        # Convert the lemmas to a single string\n",
            "        lemmas_str = ' '.join(lemmas)\n",
            "\n",
            "        # Use the Groq API to search for a matching response\n",
            "        response = self.Groq.search(lemmas_str)\n",
            "\n",
            "        # Return the response\n",
            "        return response\n",
            "\n",
            "    def respond(self, input_text):\n",
            "        response = self.process_input(input_text)\n",
            "        return response[0]\n",
            "\n",
            "def main():\n",
            "    bot = Chatbot(Groq)\n",
            "\n",
            "    # Respond to user input\n",
            "    while True:\n",
            "        user_input = input(\"User: \")\n",
            "        response = bot.respond(user_input)\n",
            "        print(f\"Groq: {response}\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "This code defines a `Chatbot` class that uses the `process_input` method to tokenize and lemmatize the user input, and then uses the `Groq` API to search for a matching response. The `respond` method returns the response from the `Groq` API.\n",
            "\n",
            "**Step 4: Run your chatbot**\n",
            "\n",
            "Run the `main` function to start your chatbot. You can interact with it by typing your messages, and it will respond accordingly.\n",
            "\n",
            "That's it! You now have a basic chatbot using the Groq API. Of course, this is just the beginning, and you can improve and customize your chatbot as needed.\n",
            "\n",
            "Remember to replace `YOUR_GROQ_API_KEY` and `YOUR_GROQ_API_SECRET` with your actual Groq API key and secret.\n",
            "You: ok thank you\n",
            "Chatbot: You're welcome! It was my pleasure to help. I hope you found the step-by-step guide helpful in getting started with creating a chatbot using the Groq API. If you have any more questions or need further assistance, don't hesitate to ask!\n",
            "\n",
            "Remember to always keep your Groq API key and secret safe and secure, as they grant access to your account and data.\n",
            "\n",
            "Have fun building your chatbot, and I hope it helps you achieve your goals!\n",
            "You: quit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Why might a chatbot built on BERT (encoder-only) struggle to answer open-ended questions?\n",
        "\n",
        "Answer 👉 Because BERT is encoder-only, it is mainly designed for understanding and classification tasks (like sentiment analysis or Q&A over short texts) It lacks a generative decoder, so it struggles to produce coherent, creative responses.\n",
        "\n",
        "Q: Why do you think meeting transcription apps like Zoom or Google Meet struggle when multiple people talk at once?\n",
        "\n",
        "Answer 👉 Speech recognition systems usually assume one dominant speaker. When multiple people overlap their voices interfere with each other creating noise making it hard for the model to separate words assign them to the right speaker and maintain transcription accuracy.\n",
        "\n",
        "Q: If you were designing a voice-based AI tutor, what qualities would you want in its TTS voice?\n",
        "\n",
        "Answer 👉 The TTS voice should be clear, natural, and well-paced, with a tone that is not so robotic . It should adjust speed.\n",
        "\n",
        "📝 Assignment 1: LLM Understanding\n",
        "\n",
        "Encoder-only models (e.g., BERT) focus on understanding input text but cannot generate long outputs.\n",
        "Decoder-only models (e.g., GPT) specialize in text generation and continuation.\n",
        "Encoder-decoder models (e.g., T5) combine both: the encoder processes input, and the decoder generates output.\n",
        "\n",
        "Encoder-only usage: Sentiment analysis\n",
        "\n",
        "Decoder-only usage: Creative story generation\n",
        "\n",
        "Encoder-decoder usage: Machine translation\n",
        "\n",
        "📝 Assignment 2: STT/TTS Exploration\n",
        "\n",
        "STT Model: DeepSpeech (Mozilla)\n",
        "\n",
        "What it does: Converts spoken audio into text.\n",
        "\n",
        "Possible application: Transcribing podcasts or lectures.\n",
        "\n",
        "TTS Model: Tacotron 2 (by Google AI)\n",
        "\n",
        "What it does: Generates natural-sounding speech from text.\n",
        "\n",
        "Possible application: Creating realistic audiobook narrations.\n",
        "\n",
        "📝 Assignment 6: Reflection\n",
        "\n",
        "Why is context memory important in chatbots?\n",
        "Because it allows the chatbot to remember past interactions, respond consistently, and provide answers that feel more natural and human-like.\n",
        "\n",
        "Why should beginners always check API limits and pricing?\n",
        "Because ignoring them can lead to unexpected costs or hitting usage caps that stop the app from working, making projects unreliable or too expensive."
      ],
      "metadata": {
        "id": "vZYflLyWbJBb"
      }
    }
  ]
}